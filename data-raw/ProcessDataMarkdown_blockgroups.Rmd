---
title: "Growing Shade methods"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  github_document:
    toc: true
always_allow_html: true
urlcolor: blue
---

The Growing Shade Project couples remote sensing data and demographic data to create insights about the intersection between the natural environment and people in real-time. 

Because there are several steps which must be done in order, this document lays those steps out logically. 

These are the files that must be in the data folder:

- mn_tracts.rda
- eva_data_main.rda
- metadata.rda
- eab.rda
- ctu_list.rda
- nhood_list.rda
- redline.rda
- trans_stops.rda
- ctu_crosswalk.rda
- nhood_crosswalk.rda
- metc_region.rda

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F,
                      cache = TRUE,
                      cache.path = "cache/")
library(tidyverse)
library(tigris)
library(sf)
source("packages_global.R")

```

# Create and export files for GEE

Google Earth Engine needs some assets created. 

```{r gee_assets}
# ######
# # Create a gridded area across the region to calibrate sentinel tree cover with 1m2 land cover tree data
# #####
# wholearea <- metc_region %>%
#   summarise(st_union(.))
# 
# # make a equal area grid; there are 704 tracts, so I want to make at least 1000 grids I think?
# g = st_make_grid(wholearea,
#                  n = c(36, 36)) %>% 
#   st_intersection(wholearea) 
# 
# geometry = st_sfc(lapply(1:length(g), function(x) st_geometrycollection()))
# df <- st_sf(id = 1:length(g), geometry = g)
# 
# # ggplot() +
# #   geom_sf(data = wholearea) +
# #   geom_sf(data = df,
# #           fill = "transparent")
# 
# sf::st_write(df, "~/Documents/GitHub/planting.shade/storymap-info/shapefiles/metc_grid.shp", append = FALSE)
# 


```


# Google Earth Engine

Need to run some things, export some things etc.

# Calibrate tree canopy coverage

For some good reasons we are going to use data from 2020 for the tree canopy coverage. But since Sentinel has a 10 meter squared pixel size, this is larger than a lot of trees. In exploring the data, it appears as if the canopy coverage from Sentinel is about two times higher than what it should be (based on aerial imagery). However, this does make sense, because Sentinel is likely saying that a 10x10m pixel has a tree, even if that tree doesn't cover the whole area. In essence, it's telling us where land is covered at least half by trees. But we can refine this further!! Let's calibrate with the outdated UMN 1 meter squared land use file. 


```{r calibrate_trees}
calibrate_trees <- read_csv("../data-raw/TreeAcres/UMNTreeAcres_metcgrid_year2020.csv") %>%
  rename(umn = `1`) %>%
  full_join(read_csv("../data-raw/TreeAcres/TreeAcres_metcgrid_year2020.csv") %>%
              rename(sentinel = `1`),
            by = 'id')

# cor.test(~ umn + sentinel,
#          data = calibrate_trees)
# cor.test(~ umn + I(sentinel^2),
#          data = calibrate_trees)

calibrate_lm <- (lm(umn ~ sentinel, data = calibrate_trees))
calibrate_lm2 <- (lm(umn ~ 0 + sentinel, data = calibrate_trees))
calibrate_lm3 <- (lm(umn ~ I(sentinel ^ 2), data = calibrate_trees))
calibrate_lm4 <- (lm(log(umn) ~ sentinel, data = calibrate_trees))
anova(calibrate_lm, calibrate_lm2, calibrate_lm3, calibrate_lm4) # the middle model is best!

# AIC(calibrate_lm); AIC(calibrate_lm2); AIC(calibrate_lm3)
anova(calibrate_lm, calibrate_lm2)
anova(calibrate_lm2, calibrate_lm3)

summary(calibrate_lm2)$r.squared # r2
summary(calibrate_lm2)$coefficients[,4] # p-value

calib_coeff <- summary(calibrate_lm2)$coefficients[,1] # coefficient
calib_coeff

calibrate_trees %>%
  ggplot(aes(x = (umn), y = (sentinel * calib_coeff))) +
  geom_point(alpha = .5) +
  geom_abline(slope=1, intercept=0, col = 'blue', lwd = 2) +
  # geom_smooth(method = "lm", fill = NA)+
  theme_minimal()  + 
  labs( x = "UMN tree acres in grid", y = "Sentinel tree acres in grid",
        title = "calibrated")
  # labs(y = expression ("Sentinel in"~m/s^2))


# calibrate_trees %>%
#   ggplot(aes(x = (sentinel), y = (umn))) +
#   geom_point(alpha = .5) +
#   geom_abline(slope=calib_coeff, intercept=0, col = 'blue', lwd = 2) +
#       stat_smooth(aes(y = umn),method = "lm", formula = y ~ x + I(x^2), size = 1, color = "red", fill = NA) +
#   # geom_smooth(method = "lm", fill = NA)+
#   theme_minimal()  +
#   labs( x = "UMN tree acres in grid", y = "Sentinel tree acres in grid",
#         title = "UNcalibrated")
# calibrate_trees %>%
#   ggplot(aes(x = (sentinel), y = log(umn))) +
#   geom_point(alpha = .5) +
#   stat_smooth(fill = NA)+
#   # geom_abline(slope=calib_coeff, intercept=0, col = 'blue', lwd = 2) +
#       # stat_smooth(aes(y = umn),method = "lm", formula = y ~ log(x), size = 1, color = "red", fill = NA) +
#   # geom_smooth(method = "lm", fill = NA)+
#   theme_minimal()  +
#   labs( x = "UMN tree acres in grid", y = "Sentinel tree acres in grid",
#         title = "UNcalibrated")
```


# Make geometry shapefiles and crosswalks

Since we're going to be making a map which shows census tracts, ctus, or neighborhoods depending on the user input, do the following:

- find centroid and zoom level of area (for reactive zooming, if I want to re-implement that)
- make a crosswalk of which tracts belong in each ctu/neighborhood
- get the tree canopy coverage of each tract
- get the count of EAB 

```{r find_centroid}

# find centroid of geographies
find_centroid <- function(x, ...) {
  points <- x %>%
    mutate(zoom = case_when(Shape_Area < 1e6 ~ 15,
                            Shape_Area < 1e8 ~ 13,
                            Shape_Area < 1e9 ~ 12,
                            TRUE ~ 11)) %>%
    st_transform(26915) %>%
    st_centroid() %>%
    st_transform(4326) %>%
    dplyr::select(!!!quos(...), geometry, zoom) %>%
    mutate(lat = unlist(map(.$geometry,1)),
           long = unlist(map(.$geometry,2))) %>%
    sf::st_drop_geometry()
  geos <- x %>%
    dplyr::select(!!!quos(...), city, geometry) %>%
    st_transform(4326)
  combo <- full_join(geos, points) %>%
    arrange(!!!(quos(...))) 
  return(combo)
}

########
# geos
######
# tracts------
mn_tracts_1 <- tigris::tracts(state = "MN",
                            county = c("Anoka", "Carver", "Dakota", "Hennepin", "Ramsey", "Scott", "Washington"))%>%
  sf::st_transform(4326) %>%
  mutate(GEO_NAME = GEOID)# %>%
  # mutate(Shape_Area = as.numeric(st_area(.)))


wi_bgs <- tigris::block_groups(state = "WI", county = c("Pierce", "Polk", "St. Croix"))
mn_bgs_1 <- tigris::block_groups(state = "MN") %>%
  bind_rows(wi_bgs) %>%
  sf::st_transform(4326) %>%
  mutate(GEO_NAME = GEOID)# %>%
  # mutate(Shape_Area = as.numeric(st_area(.)))
sf::st_write(mn_bgs_1, "/Users/escheh/Documents/GitHub/planting.shade/storymap-info/shapefiles/mn_bgs_1.shp", append = FALSE)


### neighborhoods -----------
#st paul here: https://information.stpaul.gov/City-Administration/District-Council-Shapefile-Map/dq4n-yj8b
#minneap here: https://opendata.minneapolismn.gov/datasets/communities/explore?location=44.970861%2C-93.261718%2C12.85
#brooklyn park here: but no dl: https://gis.brooklynpark.org/neighborhoodinfo/

minneap <- read_sf("../data-raw/minneapolis communities/Minneapolis_Communities.shp") %>%
  rename(GEO_NAME = CommName) %>%
  mutate(Shape_Area = as.numeric(st_area(.))) %>%
  mutate(city = "Minneapolis")

stpaul <- read_sf("../data-raw/stpaul communities/geo_export_0c076f52-d6ff-4546-b9fa-bd9980de6e8a.shp") %>%
  mutate(Shape_Area = as.numeric(st_area(.))) %>%
  rename(GEO_NAME = name2) %>%
  mutate(city = "St. Paul")

nhood_geo <- bind_rows(minneap, stpaul) %>%
  find_centroid(., GEO_NAME)


#### ctus -----------
temp <- tempfile()
temp2 <- tempfile()
download.file(
  "https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/bdry_metro_counties_and_ctus/shp_bdry_metro_counties_and_ctus.zip",
  destfile = temp
)
unzip(zipfile = temp, exdir = temp2)
list.files(temp2)

ctu_geo <- sf::read_sf(paste0(temp2, pattern = "/CTUs.shp")) %>%
  dplyr::select(CTU_NAME, Shape_Area) %>%
  add_column(city = "doesn't matter") %>%
  find_centroid(., CTU_NAME) %>%
  dplyr::select(-city) %>%
  rename(GEO_NAME = CTU_NAME) 

files <- list.files(temp2, full.names = T)
file.remove(files)


metc_region <- mn_tracts_1 %>% group_by(COUNTYFP) %>% summarise(geometry = sf::st_union(geometry))
usethis::use_data(metc_region, overwrite = TRUE)

```

Make crosswalk linking tracts to ctus and neighborhoods

```{r makecrosswalks}
# fxns to make easy -----
st_erase = function(x, y) st_difference(x, st_union(st_combine(y)))

# river layer to erase Mississippi and Minnesota rivers-------
temp <- tempfile()
download.file("ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/water_lakes_rivers/gpkg_water_lakes_rivers.zip", destfile = temp)
river_lake_buffer <- sf::read_sf(unzip(temp, "water_lakes_rivers.gpkg")) %>% 
  filter(NAME_DNR %in% c("Mississippi", "Minnesota")) #%>% #these rivers are boundaries
  # st_buffer(200) %>% #add 10m buffer
  # # st_simplify(dTolerance = 100) %>%
  # # st_buffer(300) %>%
  # st_union() %>% st_buffer(0) 
fs::file_delete("water_lakes_rivers.gpkg")

# find crosswalks
find_crosswalks <- function(x) {
  crosswalk <- x %>%
  st_transform(26915) %>%
  st_buffer(-150) %>% #buffer the perimeter of the geography
  st_erase(river_lake_buffer %>%
             st_buffer(200) %>% #buffer out rivers
             st_union() %>% 
             st_buffer(0)) %>% 
  st_intersection(mn_tracts_1 %>% 
                    dplyr::select(GEOID) %>%
                    rename(tract_id = GEOID) %>%
                    st_transform(26915)) %>%
  st_drop_geometry()
    
  return(crosswalk)
}

ctu_crosswalk <- find_crosswalks(ctu_geo)
nhood_crosswalk <- find_crosswalks(nhood_geo)

# test <- "Hilltop"
# test <- "Landfall"
# test <- "South St. Paul"
# mn_tracts_1 %>%
#   right_join(ctu_crosswalk %>% filter(GEO_NAME == test),
#              by = c("GEOID" = "tract_id")) %>%
#   ggplot()+
#   geom_sf() +
#   geom_sf(data = filter(ctu_geo, GEO_NAME ==test), fill = NA, color = "blue")
# 
# test <- "The Greater East Side"
# mn_tracts_1 %>%
#   right_join(nhood_crosswalk %>% filter(GEO_NAME == test),
#              by = c("GEOID" = "tract_id")) %>%
#   ggplot()+
#   geom_sf() +
#   geom_sf(data = filter(nhood_geo, GEO_NAME ==test), fill = NA, color = "blue")



usethis::use_data(ctu_crosswalk, overwrite = TRUE)
usethis::use_data(nhood_crosswalk, overwrite = TRUE)

wide_ctu_crosswalk_1 <- ctu_crosswalk %>%
  group_by(tract_id) %>%
  count() %>%
  left_join(ctu_crosswalk) %>%
  add_column(cities = 999) %>%
  dplyr::select(tract_id, GEO_NAME, cities, n) %>%
  # spread(cities, GEO_NAME)
  pivot_wider(names_from = cities, values_from = GEO_NAME, values_fn = list) %>%
  unnest_wider(`999`) 

wide_ctu_crosswalk <- wide_ctu_crosswalk_1 %>%
  mutate(jurisdiction = paste(`...1`, `...2`, `...3`, `...4`, `...5`, `...6`, `...7`, sep = ", ")) %>%
  dplyr::select(tract_id, jurisdiction) %>%
  mutate(jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", ""),
         jurisdiction = str_replace(jurisdiction, ", NA", "")) %>%
  rename(GEOID = tract_id)
usethis::use_data(wide_ctu_crosswalk, overwrite = TRUE)

```

- get aland for nhood and city
```{r getaland}

temp <- tempfile()
download.file("ftp://ftp.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/water_lakes_rivers/gpkg_water_lakes_rivers.zip", destfile = temp)
river_lake_all <- sf::read_sf(unzip(temp, "water_lakes_rivers.gpkg")) 


ctu_land <- ctu_geo %>%
  st_transform(26915) %>%
  st_buffer(0) %>%
  st_erase(river_lake_all %>%
             st_union() %>%
             st_buffer(0)) %>%
  mutate(ALAND = as.numeric(st_area(.)))

nhood_land <- nhood_geo %>%
  st_transform(26915) %>%
  st_buffer(0) %>%
  st_erase(river_lake_all %>%
             st_union() %>%
             st_buffer(0)) %>%
  mutate(ALAND = as.numeric(st_area(.)))


mn_tracts_2 <- mn_tracts_1 %>%
  st_transform(26915) %>%
  st_buffer(0) %>%
  st_erase(river_lake_all %>%
             st_union() %>%
             st_buffer(0)) %>%
  mutate(ALAND = as.numeric(st_area(.)))


mn_bgs_2 <- mn_bgs_1 %>%
  st_transform(26915) %>%
  st_buffer(0) %>%
  st_erase(river_lake_all %>%
             st_union() %>%
             st_buffer(0)) %>%
  mutate(ALAND = as.numeric(st_area(.)))

```


- process GEE code to link canopy with geography
  - GEE data is in repo "users/ehe/MetCoucil/GrowingShade_CanopyCoverage"
  - https://code.earthengine.google.com/a0da66053ecb26b668df4297c4ebed59

```{r gee}
tree_summary <- function(x) {
  x %>%
    left_join(canopy %>%
                rename(tract_id = GEOID10),
              by = "tract_id") %>%
    # st_drop_geometry() %>%
    group_by(GEO_NAME) %>%
    summarise(min = round(min(canopy_percent)*100, 1),
              max = round(max(canopy_percent)*100, 1),
              ntracts = n())
}



# ndvi
tract_ndvi <- read_csv("../data-raw/meanNDVI_tracts_year2020.csv",
                       col_types = cols(GEOID10 = "c", `system:index` = "c", Year = 'd', ndvi = 'd', `.geo` = 'c')) %>%
  dplyr::select(-`system:index`, -.geo, -Year)

# canopy coverage
canopy <- read_csv("../data-raw/TreeAcres/TreeAcres_tracts_year2020.csv",
                   col_types = cols(.default = "d", GEOID10 = "c")) %>%
  left_join(sf::st_drop_geometry(mn_tracts_2), by = c("GEOID10" = "GEOID")) %>%
  transmute(GEOID10 = GEOID10, 
            treeacres = `1`,
            landacres = ALAND / 4046.86,
            canopy_percent = treeacres / landacres * calib_coeff) #use calibration coefficient

## ctu canopy ----
canopy_ctu <- read_csv("../data-raw/TreeAcres/TreeAcres_ctus_year2020.csv",
                   col_types = cols(.default = "d", CTU_NAME = "c")) %>%
  left_join(ctu_land, by = c("CTU_NAME" = "GEO_NAME")) %>%
  transmute(GEO_NAME = CTU_NAME, 
            treeacres = `1`,
            landacres = ALAND / 4046.86,
            canopy_percent = treeacres / landacres * calib_coeff) 

## nhood canopy ----
canopy_nhood <- read_csv("../data-raw/TreeAcres/TreeAcres_neighborhoods_year2020.csv",
                   col_types = cols(.default = "d", GEO_NAME = "c")) %>%
  left_join(nhood_land, by = c("GEO_NAME" = "GEO_NAME")) %>%
  transmute(GEO_NAME = GEO_NAME, 
            treeacres = `1`,
            landacres = ALAND / 4046.86,
            canopy_percent = treeacres / landacres * calib_coeff) %>%
  full_join(read_csv("../data-raw/TreeAcres/UMNTreeAcres_neighborhoods_year2020_scale1.csv")) %>%
  mutate(umn_canopy = `1`/landacres)
canopy_nhood %>% arrange(canopy_percent)
# # tree raster
# treecrs <- raster::raster("./data/TreeMap_crs4326_2020.tif")
# treecrs
# 
# cuts=c(0, 1) #set breaks
# pal <- colorRampPalette(c("white","green"))
# plot((treecrs %>% crop(filter(ctu_list, GEO_NAME == "Afton"))), breaks=cuts, col = pal(7)) #plot with defined breaks
# plot((treecrs %>% crop(filter(ctu_list, GEO_NAME == "Afton")))) #plot with defined breaks


# # I did this to crop NDVI, but I'm not using NDVI anymore
# test <- reclassify(treecrs, cbind(-Inf, .5, NA), right=FALSE) 
# raster::writeRaster(test, './data/tree_raster.tif', overwrite=TRUE)

# test <- raster(x = "./data/BinaryTreeMap_crs4326_2020.tif") %>% #this is from -999 to 1; not so good
#   crop(filter(ctu_list, GEO_NAME == "Lake Elmo"))
# plot(test)
```

- get EAB counts

```{r eab}
temp <- tempfile()
temp2 <- tempfile()

download.file(
  "https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_mda/env_emerald_ash_borer/shp_env_emerald_ash_borer.zip",
  destfile = temp
)
unzip(zipfile = temp, exdir = temp2)
list.files(temp2)
eab <-
  sf::read_sf(paste0(temp2, pattern = "/eab_trees.shp")) %>%
  # filter()
  st_transform(4326) 
files <- list.files(temp2, full.names = T)
file.remove(files)

eab_counts <- function(x, ...) {
  eab %>%
    st_transform(26915) %>%
    st_intersection(x %>%
                      st_transform(26915) %>%
                      st_buffer(0)) %>%
  st_drop_geometry() %>%
  group_by(!!!quos(...)) %>%
  count() %>%
  rename(EAB = n)
}

usethis::use_data(eab, overwrite = TRUE)
```


- bind everything together for city and nhood

```{r}
nhood_list <- nhood_geo %>%
  full_join(tree_summary(nhood_crosswalk)) %>%
  full_join(eab_counts(., GEO_NAME)) %>%
    mutate(EAB = ifelse(is.na(EAB), 0, EAB)) %>%
  full_join(canopy_nhood) %>%
  arrange(city, GEO_NAME) %>%
  st_transform(4326) %>%
  group_by(city) %>%  mutate(avgcanopy = mean(canopy_percent, na.rm = T))

  # group_by(city) %>% mutate(tree = sum(treeacres), land = sum(landacres), avgcanopy = tree/land * calib_coeff,
                            # umncanopy = sum(`1`/land))

usethis::use_data(nhood_list, overwrite = TRUE)


ctu_list <- ctu_geo %>%
  full_join(tree_summary(ctu_crosswalk)) %>%
    full_join(eab_counts(., GEO_NAME)) %>%
    mutate(EAB = ifelse(is.na(EAB), 0, EAB)) %>%
  full_join(canopy_ctu) %>%
  arrange(GEO_NAME) %>%
  st_transform(4326) %>%
  mutate(avgcanopy = mean(canopy_percent, na.rm = T))
  # mutate(tree = sum(treeacres, na.rm = T), land = sum(landacres, na.rm = T), avgcanopy = tree/land * calib_coeff)

#should check credit river / credit river twp.
nhood_list %>% arrange(avgcanopy, canopy_percent)
usethis::use_data(ctu_list, overwrite = TRUE)

sf::st_write(ctu_list, "~/Documents/GitHub/planting.shade/storymap-info/shapefiles/ctu_list.shp", append = FALSE)


```



# Demographic variables and rescale

```{r demographics}
###################
# download equity considerations dataset
###################
temp <- tempfile()
download.file("https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_equity_considerations/xlsx_society_equity_considerations.zip",
  destfile = temp
)

equity <- readxl::read_xlsx(unzip(temp, "EquityConsiderations_Full.xlsx")) %>%
  janitor::clean_names() 

fs::file_delete("EquityConsiderations_Full.xlsx")


## --------------variables of interest from equity considerations
equity_data_raw <- equity %>%
  dplyr::select(tr10, 
         ppov185,
         prim_flood,
         pwhitenh,
         p_0017,
         p_65up,
         avg_temp,
         phhi_qntl1,
         green_roof,
         env_cancer,
         luse_green,
         tr_ej,
         holc_pred,
         mdhhincnow,
         pd_any,
         pblacknh,
         pasiannh,
         phisppop,
         pothmultnh,
         pamindnh,
         pwk_nowork,
         pownhome,
         # # for equity considerations talk
         # p_usborn,
         # ppov500rat,
         # pothmultnh,
         # pbanc_totl, pbanc_afri, pbanc_afam, parac_totl, parac_aind, parac_hmon, plat_totl, pind_totl, pind_dako,
         # pind_ojib, plat_mexi, plat_ecua,
         # ppov185,
         # ppov500,
         # ppov500rat,
         # mdhhincnow,
         # phhi_qntl1,
         # phhi_qntl5,
         # mdern_ftyr, aca, acp
         ) %>%
  rowwise() %>%
  mutate(luse_notgreen = 1 - luse_green,
         pbipoc = 1 - pwhitenh,
         holc_pred = if_else(is.na(holc_pred), 0, holc_pred),
         sens_age = p_0017 + p_65up) %>% #"mutate" reformats any variables that need it
  dplyr::select(-luse_notgreen,#and then I want to remove the variable I don't need anymore
         -pwhitenh) 


##########
# CDC health data
#########
# variable options are documented here: https://www.cdc.gov/places/measure-definitions/index.html
# api token: https://chronicdata.cdc.gov/profile/edit/developer_settings

library("RSocrata")
#metadata https://dev.socrata.com/foundry/chronicdata.cdc.gov/cwsq-ngmh

health <- read.socrata(
  "https://chronicdata.cdc.gov/resource/cwsq-ngmh.json?$where=countyfips in('27003', '27019', '27037', '27053', '27123', '27139', '27163')",
  app_token = "D1kEEJEDVBpDppDIdDmwNXeVT",
  email     = "ellen.esch@metc.state.mn.us",
  password  ="TQfY5%Q3xY") %>%
  rename(GEOID10 = locationname)

health
names(health)
levels(as.factor(health$measure))

health2 <- health %>%
  filter(measure %in% c("Current asthma among adults aged >=18 years",
                        "Chronic obstructive pulmonary disease among adults aged >=18 years",
                        "Mental health not good for >=14 days among adults aged >=18 years",
                        "Physical health not good for >=14 days among adults aged >=18 years")) %>%
  dplyr::select(GEOID10, measureid, data_value) %>%
  mutate(data_value = as.numeric(data_value) / 100) %>% #change to fraction
  pivot_wider(names_from = measureid, values_from = data_value) %>%
  rename(tr10 = GEOID10)

###################
# combine data sources
###################

eva_data_raw <- equity_data_raw %>% 
  full_join(canopy %>% rename(tr10 = GEOID10)) %>%
  full_join(tract_ndvi %>% rename(tr10 = GEOID10)) %>%
  full_join(health2) %>%
  mutate(ndvi2 = ndvi,
         canopy_percent2 = canopy_percent) %>%
  rename(tract_string = tr10) #and for this project, I need to rename the tract variable

###################
# add some human-readable metadata
###################

## -------------------------------describe data
#cc (climate change preset) = prim_flood, avg_temp, ndvi
#ej (environmental justice preset) = pbipoc, phhi_qntl1, prim_flood, avg_temp, ndvi
#ph (public health preset)
eva_data_codes <- tribble(~variable, ~name, ~type, ~interpret_high_value, ~cc, ~ej, ~ph, ~cons,
                          "ppov185",	"% people with income <185% of the poverty threshold", "dollar", "high_opportunity", 0, 1, 0, 0,
                          "prim_flood", "% developed acres in primary flood zone", "environment", "high_opportunity", 1, 1, 0, 0,
                          "pbipoc", "race, % people of color", "people", "high_opportunity", 0, 1, 0, 0,
                          "p_0017", "age, % age 17 or younger", "people",  "high_opportunity", 0, 0, 0, 0, 
                          "p_65up", "age, % age 65 or older", "people",  "high_opportunity", 0, 0, 0,  0,
                          "avg_temp", "Temperature on hot summer day", "environment",  "high_opportunity", 1, 1, 1, 0,
                          # "phhi_qntl1", "% households with annual income less than $35,000 (bottom quintile of households)", "people",  "high_opportunity", 0, 1, 0, 0,
                          # "green_roof", "Water holding potential of green roofs on commercial bldgs", "environment",  "high_opportunity", 
                          "env_cancer", "Lifetime cancer risk from air toxics", "health", "high_opportunity", 0, 1, 1,  0,
                          # "luse_notgreen", "% of tract NOT used for green space", "environment", "high_opportunity"
                          "ndvi", "Greenness (2020 NDVI)", "environment", "low_opportunity", 1, 0, 1,  0,
                          "ndvi2", "Greenness (2020 NDVI) - for conservation", "environment", "high_opportunity", 0, 0, 0, 1,
                          "tr_ej", "Area of Environmental Justice Concern", "environment", "high_opportunity", 0, 1, 0, 0,
                          "holc_pred", "% of tract's land acreage redlined", "environment", "high_opportunity", 0, 1, 0, 0,
                          "canopy_percent", "Tree canopy in 2020 (%)", "environment", "low_opportunity", 1, 0, 1, 0,
                          "canopy_percent2", "Tree canopy in 2020 (%) - for conservation", "environment", "high_opportunity", 0, 0, 0, 1,
                          "mdhhincnow", "Median household income", "dollar", "low_opportunity", 0, 0, 0, 0, #, 2015-2019 period (in 2019 dollars)
                          "sens_age", "age, % 17 or younger and 65 or older", "people", "high_opportunity", 0,0,1,0,
                          "pd_any", "% people with any disability", "people", "high_opportunity", 0, 0, 0, 0,
                          "pblacknh", "race, % Black or African American", "people", "high_opportunity", 0, 0, 0, 0,
                          "pothmultnh", "race, % Multiracial or other", "people", "high_opportunity", 0, 0, 0, 0,
                          "pasiannh", "race, % Asian", "people", "high_opportunity", 0, 0, 0, 0,
                          "phisppop", "race, % Hispanic or Latino", "people", "high_opportunity", 0, 0, 0, 0,
                          "pamindnh", "race, % Indigenous", "people", "high_opportunity", 0, 0, 0, 0,
                          "pwk_nowork", "% of unemployed residents", "dollar", "high_opportunity", 0, 0, 0, 0, # age 16-64 who did not work in past 12 months
                          "pownhome", "% of residents who own their home", "dollar", "high_opportunity", 0,0,0,0,
                          "MHLTH", "Mental health not good for >=14 days among adults (%)", "health", "high_opportunity", 0,0,0,0,
                          "PHLTH", "Physical health not good for >=14 days among adults (%)", "health", "high_opportunity", 0,0,0,0,
                          "COPD", "Chronic obstructive pulmonary disease among adults (%)", "health", "high_opportunity", 0,0,0,0,
                          "CASTHMA", "Asthma among adults (%)", "health", "high_opportunity", 0,0,0,0
                          )
# eva_data_codes %>% filter(ph == 1)

###################
# #create final dataset - no spatial data here
# #note: spatial data should be joined after any summarizing is done to save some computation time
###################

# #long data
eva_data_main <- eva_data_raw %>%
  pivot_longer(names_to = "variable", values_to = "raw_value", -tract_string) %>% #end the code after this line if you just want the reshaped data
  group_by(variable) %>%
  mutate(MEAN = mean(raw_value, na.rm = T),
         SD = sd(raw_value, na.rm = T),
         MIN = min(raw_value, na.rm = T),
         MAX = max(raw_value, na.rm = T),
         COUNT = as.numeric(sum(!is.na(raw_value))),
         z_score = (raw_value - MEAN)/SD) %>%
  
  full_join(eva_data_codes, by = 'variable') %>%
  
  # #we want high opportunity to be a high value, so this reorders those values if needed
  # mutate(opportunity_zscore = case_when(interpret_high_value == "high_opportunity" ~ z_score,
  #                                       interpret_high_value == "low_opportunity" ~ z_score * (-1),
  #                                         TRUE ~ NA_real_)) %>%
  
  #create nominal weights
  mutate(weights_nominal = case_when(interpret_high_value == "high_opportunity" ~ (raw_value - MIN) / (MAX - MIN) * 10,
                                     interpret_high_value == "low_opportunity" ~ 10 - (raw_value - MIN) / (MAX - MIN) * 10,
                                     TRUE ~ NA_real_)) %>%
  
  #Weights Standard Score
  mutate(weights_scaled = case_when(interpret_high_value == "high_opportunity" ~ pnorm(z_score) * 10,
                                    interpret_high_value == "low_opportunity" ~ (10 - pnorm(z_score) * 10),
                                    TRUE ~ NA_real_)) %>%
  
  #weights rank
  mutate(weights_rank = case_when(interpret_high_value == "high_opportunity" ~ min_rank(desc(weights_nominal)) / COUNT * 10,
                                  interpret_high_value == "low_opportunity" ~ min_rank(desc(weights_nominal)) / COUNT * 10,
                                  TRUE ~ NA_real_)) %>%
  
  # #rank
  mutate(overall_rank = case_when(interpret_high_value == "high_opportunity" ~ min_rank(desc(as.numeric(weights_nominal))),
                                  interpret_high_value == "low_opportunity" ~ min_rank(desc(as.numeric(weights_nominal))))) %>%
  # 
  #clean
  dplyr::select(-MEAN, -SD, -MIN, -MAX)  %>%
  full_join(wide_ctu_crosswalk %>% rename(tract_string = GEOID))

########
# save data
########

#this works if you're in a package
usethis::use_data(eva_data_main, overwrite = TRUE)

#otherwise use this
# write_csv(eva_data_main, "./eva_data_main.csv")

# ########
# # create metadata
# #########
md1 <- eva_data_main %>% group_by(variable) %>% summarise(MEANRAW = mean(raw_value, na.rm = T),
                                                          MEANSCALED = mean(weights_scaled, na.rm = T))
metadata <- eva_data_main %>%
  dplyr::group_by(type, name, variable, interpret_high_value, cc, ej, ph, cons) %>%
  dplyr::count() %>%
  dplyr::ungroup() %>%
  full_join(md1) %>%
  mutate(niceinterp = 
               case_when(interpret_high_value == "high_opportunity" ~ "Higher",
                         TRUE ~ "Lower"),
         nicer_interp = case_when(niceinterp == "Lower" ~ "Lower values = higher priority", 
                                  variable == "ndvi2" ~ "Higher values = higher priority",
                                  variable == "canopy_percent2" ~ "Higher values = higher priority",
                                  TRUE ~ ""))

usethis::use_data(metadata, overwrite = TRUE)

```

# Demographics but at block level

```{r blocksdemos}

##########
# equity considerations data in some cases
#########
equity_bg <- read_csv("/Volumes/shared/CommDev/Research/Research/EquityConsiderationsData/2_OutputData/CSV/Release_20210225/EquityConsiderationsBlockGroups.csv",
                   col_types = cols( .default = "?", BG10 = "c")) %>%
  janitor::clean_names() 
equity_data_raw_bg <- equity_bg %>%
  select(bg10,#tr10, 
         ppov185,
         prim_flood,
         pwhitenh,
         p_0017,
         p_65up,
         avg_temp,
         phhi_qntl1,
         green_roof,
         env_cancer,
         luse_green,
         tr_ej,
         holc_pred,
         mdhhincnow,
         pd_any,
         pwk_nowork,
         pownhome,
         pblacknh,
         pasiannh,
         phisppop,
         pamindnh,
         pothmultnh,
         pbipoc
         ) %>%
  rowwise() %>%
  mutate(luse_notgreen = 1 - luse_green,
         # pbipoc = 1 - pwhitenh,
         holc_pred = if_else(is.na(holc_pred), 0, holc_pred),
         sens_age = p_0017 + p_65up) %>% #"mutate" reformats any variables that need it
  select(-luse_notgreen,#and then I want to remove the variable I don't need anymore
         -pwhitenh) 


###################
# download acs dataset
###################
temp <- tempfile()
download.file("https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census_acs/xlsx_society_census_acs.zip",
  destfile = temp
)

acs <- readxl::read_xlsx(unzip(temp, "CensusACSBlockGroup.xlsx")) %>%
  janitor::clean_names() 

fs::file_delete("CensusACSBlockGroup.xlsx")


## --------------variables of interest from equity considerations
acs_data_raw <- acs %>%
  select(geog_unit, 
         pov185rate,
         poptotal,
         whitenh,
         ageunder18,
         age65up,
         medianhhi,
         blacknh,
         asiannh,
         hisppop,
         amindnh,
         homeownpct
         ) %>%
  rowwise() %>%
  transmute(
    bg10 = geog_unit,
    ppov185 = pov185rate,
    mdhhincnow = medianhhi,
    pownhome = homeownpct,
    pwhitenh = whitenh / poptotal,
         pblacknh = blacknh / poptotal,
         pasiannh = asiannh / poptotal,
         phisppop = hisppop / poptotal,
         pamindnh = amindnh / poptotal,
         pbipoc = 1 - pwhitenh,
         p_0017 = ageunder18 / poptotal,
         p_65up = age65up / poptotal,
         sens_age = p_0017 + p_65up) 



###################
# combine data sources
###################

eva_data_raw_bg <- acs_data_raw %>%
  filter(!str_detect(bg10, "27003|27019|27037|27053|27123|27139|27163")) %>%
  full_join(equity_data_raw_bg) %>%

# a <- eva_data_raw_bg %>%
#   mutate(cty = str_sub(bg10, 1, 5)) %>%
#   filter(str_detect(cty, "55"))
# levels(as.factor(a$cty))
  # full_join(acs_data_raw)
  full_join(canopy %>% rename(tr10 = GEOID10)) %>%
  full_join(tract_ndvi %>% rename(tr10 = GEOID10)) %>%
  full_join(health2) %>%
  mutate(ndvi2 = ndvi,
         canopy_percent2 = canopy_percent) %>%
  rename(tract_string = tr10) #and for this project, I need to rename the tract variable

  filter(equity_data_raw_bg, bg10 == "270030501071") %>%
    full_join(
  filter(acs_data_raw, bg10 == "270030501071"))
  
`%notin%` <- Negate(`%in%`)
  
filter(acs_data_raw,bg10 %notin% c(eva_data_raw_bg$bg10))


###################
# add some human-readable metadata
###################

## -------------------------------describe data
#cc (climate change preset) = prim_flood, avg_temp, ndvi
#ej (environmental justice preset) = pbipoc, phhi_qntl1, prim_flood, avg_temp, ndvi
#ph (public health preset)
eva_data_codes <- tribble(~variable, ~name, ~type, ~interpret_high_value, ~cc, ~ej, ~ph, ~cons,
                          "ppov185",	"% people with income <185% of the poverty threshold", "people", "high_opportunity", 0, 1, 0, 0,
                          "prim_flood", "% developed acres in primary flood zone", "environment", "high_opportunity", 1, 1, 0, 0,
                          "pbipoc", "% people of color", "people", "high_opportunity", 0, 1, 0, 0,
                          "p_0017", "% people age 17 or younger", "people",  "high_opportunity", 0, 0, 0, 0, 
                          "p_65up", "% people age 65 or older", "people",  "high_opportunity", 0, 0, 0,  0,
                          "avg_temp", "Land surface temp on hot summer day", "environment",  "high_opportunity", 1, 1, 1, 0,
                          # "phhi_qntl1", "% households with annual income less than $35,000 (bottom quintile of households)", "people",  "high_opportunity", 0, 1, 0, 0,
                          # "green_roof", "Water holding potential of green roofs on commercial bldgs", "environment",  "high_opportunity", 
                          "env_cancer", "Lifetime cancer risk from air toxics", "people", "high_opportunity", 0, 1, 1,  0,
                          # "luse_notgreen", "% of tract NOT used for green space", "environment", "high_opportunity"
                          "ndvi", "Average greenness (2020 NDVI)", "tree", "low_opportunity", 1, 0, 1,  0,
                          "ndvi2", "Average greenness (2020 NDVI) - for conservation", "tree", "high_opportunity", 0, 0, 0, 1,
                          "tr_ej", "Area of Environmental Justice Concern", "people", "high_opportunity", 0, 1, 0, 0,
                          "holc_pred", "Share of tract's land acreage redlined", "people", "high_opportunity", 0, 1, 0, 0,
                          "canopy_percent", "% tree canopy coverage in 2020", "tree", "low_opportunity", 1, 0, 1, 0,
                          "canopy_percent2", "% tree canopy coverage in 2020 - for conservation", "tree", "high_opportunity", 0, 0, 0, 1,
                          "mdhhincnow", "Median household income, 2015-2019 period (in 2019 dollars)", "people", "low_opportunity", 0, 0, 0, 0,
                          "sens_age", "% people 17 or younger and 65 or older", "people", "high_opportunity", 0,0,1,0,
                          "pd_any", "% people with any disability", "people", "high_opportunity", 0, 0, 0, 0,
                          "pblacknh", "% residents identifying as Black or African American", "people", "high_opportunity", 0, 0, 0, 0,
                          "pasiannh", "% residents identifying as Asian", "people", "high_opportunity", 0, 0, 0, 0,
                          "phisppop", "% residents identifying as Hispanic or Latino", "people", "high_opportunity", 0, 0, 0, 0,
                          "pamindnh", "% residents identifying as Indigenous", "people", "high_opportunity", 0, 0, 0, 0,
                          "pwk_nowork", "% of residents age 16-64 who did not work in past 12 months", "people", "high_opportunity", 0, 0, 0, 0,
                          "pownhome", "% of residents who own their home", "people", "high_opportunity", 0,0,0,0,
                          "MHLTH", "Mental health not good for >=14 days among adults aged >=18 years (%)", "people", "high_opportunity", 0,0,0,0,
                          "PHLTH", "Physical health not good for >=14 days among adults aged >=18 years (%)", "people", "high_opportunity", 0,0,0,0,
                          "COPD", "Chronic obstructive pulmonary disease among adults aged >=18 years (%)", "people", "high_opportunity", 0,0,0,0,
                          "CASTHMA", "Current asthma among adults aged >=18 years (%)", "people", "high_opportunity", 0,0,0,0
                          )
eva_data_codes %>% filter(ph == 1)

###################
# #create final dataset - no spatial data here
# #note: spatial data should be joined after any summarizing is done to save some computation time
###################

# #long data
eva_data_main <- eva_data_raw %>%
  pivot_longer(names_to = "variable", values_to = "raw_value", -tract_string) %>% #end the code after this line if you just want the reshaped data
  group_by(variable) %>%
  mutate(MEAN = mean(raw_value, na.rm = T),
         SD = sd(raw_value, na.rm = T),
         MIN = min(raw_value, na.rm = T),
         MAX = max(raw_value, na.rm = T),
         COUNT = as.numeric(sum(!is.na(raw_value))),
         z_score = (raw_value - MEAN)/SD) %>%
  
  full_join(eva_data_codes, by = 'variable') %>%
  
  # #we want high opportunity to be a high value, so this reorders those values if needed
  # mutate(opportunity_zscore = case_when(interpret_high_value == "high_opportunity" ~ z_score,
  #                                       interpret_high_value == "low_opportunity" ~ z_score * (-1),
  #                                         TRUE ~ NA_real_)) %>%
  
  #create nominal weights
  mutate(weights_nominal = case_when(interpret_high_value == "high_opportunity" ~ (raw_value - MIN) / (MAX - MIN) * 10,
                                     interpret_high_value == "low_opportunity" ~ 10 - (raw_value - MIN) / (MAX - MIN) * 10,
                                     TRUE ~ NA_real_)) %>%
  
  #Weights Standard Score
  mutate(weights_scaled = case_when(interpret_high_value == "high_opportunity" ~ pnorm(z_score) * 10,
                                    interpret_high_value == "low_opportunity" ~ (10 - pnorm(z_score) * 10),
                                    TRUE ~ NA_real_)) %>%
  
  #weights rank
  mutate(weights_rank = case_when(interpret_high_value == "high_opportunity" ~ min_rank(desc(weights_nominal)) / COUNT * 10,
                                  interpret_high_value == "low_opportunity" ~ min_rank(desc(weights_nominal)) / COUNT * 10,
                                  TRUE ~ NA_real_)) %>%
  
  # #rank
  mutate(overall_rank = case_when(interpret_high_value == "high_opportunity" ~ min_rank(desc(as.numeric(weights_nominal))),
                                  interpret_high_value == "low_opportunity" ~ min_rank(desc(as.numeric(weights_nominal))))) %>%
  # 
  #clean
  select(-MEAN, -SD, -MIN, -MAX)  %>%
  full_join(wide_ctu_crosswalk %>% rename(tract_string = GEOID))

########
# save data
########

#this works if you're in a package
usethis::use_data(eva_data_main, overwrite = TRUE)

#otherwise use this
# write_csv(eva_data_main, "./eva_data_main.csv")

# ########
# # create metadata
# #########
md1 <- eva_data_main %>% group_by(variable) %>% summarise(MEANRAW = mean(raw_value, na.rm = T),
                                                          MEANSCALED = mean(weights_scaled, na.rm = T))
metadata <- eva_data_main %>%
  dplyr::group_by(type, name, variable, interpret_high_value, cc, ej, ph, cons) %>%
  dplyr::count() %>%
  dplyr::ungroup() %>%
  full_join(md1) %>%
  mutate(niceinterp = 
               case_when(interpret_high_value == "high_opportunity" ~ "Higher",
                         TRUE ~ "Lower"))

usethis::use_data(metadata, overwrite = TRUE)

```



# THink about temperature and trees

```{r}

#some agricultural communities have high greenness and temperature, but low tree canopy
eva_data_main %>%
  filter(variable %in% c("avg_temp", "canopy_percent")) %>%
  select(tract_string, variable, raw_value) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  ggplot(aes(x = canopy_percent, y = avg_temp)) +
  geom_point(alpha = .6) 


# ndvi and temp are in the same model; so of course this is a nice relationship
eva_data_main %>%
  filter(variable %in% c("avg_temp", "ndvi")) %>%
  select(tract_string, variable, raw_value) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  ggplot(aes(x = ndvi, y = avg_temp)) +
  geom_point(alpha = .6) 

```




# Highest priority by area

For storymap??

And to make tract database

```{r}
highest_p <- function(x) {
  test <- enquo(x)
  
   eva_data_main %>%
  filter(name %in% (metadata %>%
                      filter(!!test == 1)))
}

highest_p(ph)

highest_p <- function(group_var) {
  selectedvars <- metadata %>%
    filter(!!enquo(group_var) == 1) %>%
    .[,2]
  eva_data_main %>% 
    filter(name %in% selectedvars$name) %>%
      group_by(tract_string) %>%
      summarise(MEAN = mean(weights_scaled, na.rm = T))
}

priority_summary_1 <-highest_p(ph) %>% rename(`Public health` = MEAN) %>%
  full_join(highest_p(cons) %>% rename(Conservation = MEAN)) %>%
  full_join(highest_p(ej) %>% rename(`Environmental justice` = MEAN)) %>%
  full_join(highest_p(cc) %>% rename(`Climate change` = MEAN)) %>%
  pivot_longer(names_to = "preset", values_to = "score", -tract_string) 

priority_summary <- priority_summary_1 %>%
  group_by(tract_string) %>%
  summarise(score = max(score)) %>%
  left_join(priority_summary_1) %>%
  rename(highest_priority = preset) %>%
  rename(GEOID = tract_string)



mn_tracts <- mn_tracts_1 %>%
  full_join(wide_ctu_crosswalk) %>%
      full_join(eab_counts(., GEOID)) %>%
    mutate(EAB = ifelse(is.na(EAB), 0, EAB)) %>%
  full_join(canopy %>% rename(GEOID = GEOID10)) %>%
  full_join(priority_summary) %>%
  full_join(priority_summary_1%>%
              group_by(preset) %>% 
              mutate(rank = rank(-score)) %>%
              select(-score) %>%
              pivot_wider(names_from = preset, values_from = rank)
            %>% rename(GEOID = tract_string)) %>%
  mutate(avgcanopy = mean(canopy_percent, na.rm = T)) %>%
  st_as_sf() %>%
      st_transform(4326)

usethis::use_data(mn_tracts, overwrite = TRUE)


sf::st_write(mn_tracts, "~/Documents/GitHub/planting.shade/storymap-info/shapefiles/mn_tracts.shp", append = FALSE)



# library(leaflet)
# factpal <- colorFactor(palette = c(
#                        "ej" = "purple", #black
#                        "cons" = "#b1d3fc", #hispanic
#                        "cc" = "green",#"#996633", #indg
#                        "ph" = "#E69F00"),
#                        c("ej", "cons", "cc", "ph"))#,
                       
                       
# leaflet() %>%
#   addPolygons(data = test,
#               fillColor = ~factpal(test[[20]]),
#               fillOpacity = .5,
#               weight = .5,
#               color = "#666666",
#               popup = ~paste0("Geography ID: ", test$GEOID,
#                                          "<br>", ": ", test$highest_priority
#                          )) %>%
#   addLegend(title = "highest",
#                          position = "bottomleft",
#                          # group = "Census data",
#                          # layerId = "Census data",
#                          pal = factpal,
#                          values = test[[20]]
#                        )


# %>%
  # full_join(ctu_crosswalk)

```


can i improve distribution maps?

```{r}
mn_tracts %>%
st_drop_geometry() %>%
  ggplot() +
  geom_jitter(aes(x = canopy_percent, y = 1))

ggplot()+
  geom_jitter(width = 0, height = .2,
              aes(x = canopy_percent, y = "All Cities"),
              alpha = .4,
              data = ctu_list) +
  geom_jitter(width = 0, height = .2,
              aes(x = canopy_percent, y = "All Cities"),
              data = filter(ctu_list, 
                            GEO_NAME == "St. Paul"),
              pch = 21, col = "black", fill = "red", size = 3) +
  
  
  # geom_jitter(width = 0, height = .2,
  #             aes(x = canopy_percent, y = 'Tracts'), 
  #             alpha = .4,
  #             data = st_drop_geometry(mn_tracts)) +
    geom_jitter(width = 0, height = .2,
              aes(x = canopy_percent, y = 'aa_St.Paul_tracts'), 
              data = filter(st_drop_geometry(mn_tracts),
              jurisdiction == "St. Paul"),
              pch = 21, col = "black", fill = "red", size = 3) +
  
  # geom_jitter(width = 0, 
  #             aes(x = canopy_percent, y = "Nhood"),
  #             alpha = .5,
  #             data = nhood_list) +
  # geom_jitter(width = 0, 
  #             aes(x = canopy_percent, y = "Nhood"),
  #             data = filter(nhood_list, 
  #                           city == "St. Paul"),
  #             col = councilR::colors$cdGreen, size = 3) +
  

  councilR::council_theme() +
          scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = "Tree canopy cover",
       y = "Geography",
       title = "St. Paul")

ggplot()+
  geom_jitter(width = 0, height = .2,
              aes(x = canopy_percent, y = "All Cities"),
              alpha = .4,
              data = ctu_list) +
  geom_jitter(width = 0, height = .2,
              aes(x = canopy_percent, y = "All Cities"),
              data = filter(ctu_list, 
                            GEO_NAME == "Birchwood Village"),
              pch = 21, col = "black", fill = "red", size = 3) +
  
  
  # geom_jitter(width = 0, height = .2,
  #             aes(x = canopy_percent, y = 'Tracts'), 
  #             alpha = .4,
  #             data = st_drop_geometry(mn_tracts)) +
    geom_jitter(width = 0, height = .2,
              aes(x = canopy_percent, y = 'aa_Birchwood Village_tracts'), 
              data = filter(st_drop_geometry(mn_tracts),
              str_detect(jurisdiction, "Birchwood Village")),
              pch = 21, col = "black", fill = "red", size = 3) +
  
  # geom_jitter(width = 0, 
  #             aes(x = canopy_percent, y = "Nhood"),
  #             alpha = .5,
  #             data = nhood_list) +
  # geom_jitter(width = 0, 
  #             aes(x = canopy_percent, y = "Nhood"),
  #             data = filter(nhood_list, 
  #                           city == "St. Paul"),
  #             col = councilR::colors$cdGreen, size = 3) +
  

  councilR::council_theme() +
          scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = "Tree canopy cover",
       y = "Geography",
       title = "Birchwood Village")

```


can i improve priortization?

```{r}
mn_tracts %>% 
  st_drop_geometry() %>%
  filter((jurisdiction == "St. Paul")) %>%
  pivot_longer(names_to = "preset", values_to = "rank", c(`Public health`:`Climate change`)) %>%
  ggplot() + 
  scale_x_continuous( limits = c(1, 704), labels = c(1, 250, 500, 704), breaks = c(1, 250, 500, 704)) +
      ylim(0, 1) +
  # scale_y_continuous(limits = c(0,1), expand = c(3,3))+
      geom_segment(aes(x = rank, xend = rank, y = 0, yend = .8)) +
      # geom_vline(aes(xintercept = rank)) +
      geom_segment(aes(x = 1, xend = 700, y = 0, yend = 0)) +
  facet_wrap(~preset, ncol = 1) +
  expand_limits(x = 2, y = 20) +
  labs(title = "St. Paul") +
  theme_minimal() +
  theme(axis.text.y = element_blank(),
            axis.title.y = element_blank(),
            panel.grid.major.y = element_blank(),
            panel.grid.minor.y = element_blank(),
            panel.grid.major.x = element_blank(),
            panel.grid.minor.x = element_blank())
```




```{r}
# STATS
library(factoextra)

ana <- eva_data_main %>%
  select(tract_string, variable, z_score) %>%
  pivot_wider(names_from = variable, values_from = z_score) %>%
  filter(!is.na(ppov185)) %>%
  select(-ndvi2, -canopy_percent2,
         # -p_0017, -p_65up, 
         -sens_age,
         -pwk_nowork,
         # -pasiannh, -phisppop, -pamindnh, -pblacknh,
         -pbipoc)

# ana[, -1] %>% summary()

ec.pca <- prcomp(ana[, -1], scale = T)
fviz_eig(ec.pca)
# 
# fviz_pca_var(ec.pca,
#              col.var = "contrib", # Color by contributions to the PC
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
#              repel = TRUE     # Avoid text overlapping
#              )


fviz_pca_biplot(ec.pca, repel = TRUE,
                label = 'var',
                col.var = "black", #2E9FDF", # Variables color
                col.ind = "#696969",  # Individuals color,
                alpha.ind = .3
                )
```


```{r}
library(corrplot)
library("Hmisc")


race <- eva_data_main %>%
  select(tract_string, variable, z_score) %>%
  pivot_wider(names_from = variable, values_from = z_score) %>%
  filter(!is.na(ppov185)) %>%
  select(ndvi, canopy_percent, 
         pasiannh, phisppop, pamindnh, pblacknh,
         pbipoc,
         pd_any,
         mdhhincnow, ppov185,
         p_usborn,
         holc_pred,
         avg_temp,# prim_flood,
         p_65up, p_0017) %>%
  rename(NDVI = ndvi,
         `Tree canopy` = canopy_percent,
         `Disability, % any` = pd_any,
         `Race, % Asian` = pasiannh,
         `Race, % Am. Indian` = pamindnh,
         `Race, % Hispanic` = phisppop,
         `Race, % Black` = pblacknh,
         `Race, % BIPOC` = pbipoc,
         `SE, median income` = mdhhincnow,
         `SE,  <185% poverty threshold` = ppov185,
         `Migration, % US born` = p_usborn,
         `Historic, % redlined` = holc_pred,
         `Env., summer temp` = avg_temp,
         # `Env., flood zone` = prim_flood,
         `Age, % over 64` = p_65up,
         `Age, % under 18` = p_0017)

res <- cor(race)

# cor_2 <- rcorr(as.matrix(race))
# cor_2$P %>% 
#   add_column(var = rownames(cor_2$r))

# round(res, 2)
# corrplot(res, type = "upper", order = "hclust", 
#          tl.col = "black", tl.srt = 45)

as_tibble(res) %>%
  add_column(var = rownames(res)) %>%
  mutate(var = fct_reorder(var, (`Tree canopy`))) %>%
    ggplot(aes(x = var, y = `Tree canopy`)) +
  geom_bar(stat = 'identity') +
  theme_minimal() +
  labs(x = "Variable", y = "Correlation coefficient with \n'Tree canopy coverage'") +
  coord_flip()
# rownames(res)
```

```{r flooding}

race <- eva_data_main %>%
  select(tract_string, variable, z_score) %>%
  pivot_wider(names_from = variable, values_from = z_score) %>%
  filter(!is.na(ppov185)) %>%
  select(ndvi, canopy_percent, 
         pasiannh, phisppop, pamindnh, pblacknh,
         pbipoc,
         pd_any,
         mdhhincnow, ppov185,
         p_usborn,
         holc_pred,
         avg_temp, prim_flood,
         p_65up, p_0017) %>%
  rename(NDVI = ndvi,
         `Tree canopy` = canopy_percent,
         `Disability, % any` = pd_any,
         `Race, % Asian` = pasiannh,
         `Race, % Am. Indian` = pamindnh,
         `Race, % Hispanic` = phisppop,
         `Race, % Black` = pblacknh,
         `Race, % BIPOC` = pbipoc,
         `SE, median income` = mdhhincnow,
         `SE,  <185% poverty threshold` = ppov185,
         `Migration, % US born` = p_usborn,
         `Historic, % redlined` = holc_pred,
         `Env., summer temp` = avg_temp,
         `Flood zone` = prim_flood,
         `Age, % over 64` = p_65up,
         `Age, % under 18` = p_0017)

res <- cor(race)

# cor_2 <- rcorr(as.matrix(race))
# cor_2$P %>% 
#   add_column(var = rownames(cor_2$r))

# round(res, 2)
# corrplot(res, type = "upper", order = "hclust", 
#          tl.col = "black", tl.srt = 45)

as_tibble(res) %>%
  add_column(var = rownames(res)) %>%
  mutate(var = fct_reorder(var, (`Flood zone`))) %>%
    ggplot(aes(x = var, y = `Flood zone`)) +
  geom_bar(stat = 'identity') +
  theme_minimal() +
  labs(x = "Variable", y = "Correlation coefficient with \n'Areas at risk of flooding'") +
  coord_flip()
# rownames(res)

```



```{r}
library(cowplot)
race_fig<-eva_data_main %>%
  select(tract_string, variable, raw_value) %>%
  filter(variable %in% c("canopy_percent", "pbipoc")) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  ggplot(aes(x = pbipoc, y = canopy_percent)) +
  geom_point(pch = 21, col = "grey40") +#colors$suppGray) +
  geom_smooth(col = councilR::colors$cdGreen, fill = NA, lwd = 3, method = 'lm') +
  councilR::council_theme() +
  scale_x_continuous(labels = scales::percent, limits = c(0, .45))+#, trans = log2_trans()) +
  scale_y_continuous(labels = scales::percent)+#, trans = log2_trans()) +
  labs(x = "Residents identifying as BIPOC (%)", y = "")


inc_fig <-eva_data_main %>%
  select(tract_string, variable, raw_value) %>%
  filter(variable %in% c("canopy_percent", "mdhhincnow")) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  ggplot(aes(x = mdhhincnow, y = canopy_percent)) +
  geom_point(pch = 21, col = "grey40") +#colors$suppGray) +
  geom_smooth(col = councilR::colors$cdGreen, fill = NA, lwd = 3, method = 'lm') +
  councilR::council_theme() +
    scale_y_continuous(labels = scales::percent, limits = c(0, .45))+#, trans = log2_trans()) +
  scale_x_continuous(labels = scales::dollar)+#, trans = log2_trans()) +
  labs(x = "Median household income ($)", y = "")

fig_equity <- plot_grid(race_fig, inc_fig, labels = "AUTO")#, age, cost)
fig_equity
ggsave("~/Desktop/equity.png",fig_equity,  width = 10, height = 4.5, units = "in", device = "png")

```




```{r}
eva_data_main %>%
  select(tract_string, variable, raw_value) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  select(tract_string, canopy_percent, 
         pbanc_totl, pbanc_afri, pbanc_afam, parac_totl, parac_aind, parac_hmon, plat_totl, pind_totl, pind_dako,
         pind_ojib, plat_mexi, plat_ecua) %>%
  rename(
    `Asian, Asian Indian` = parac_aind,
    `Black, African American` = pbanc_afam,
    `Indigenous, Dakota/Sioux` = pind_dako,
    `Indigenous, Ojibwe/Chippewa/Anishinabe` = pind_ojib,
    `Asian, Hmong` = parac_hmon,
    `Black, sub-Saharan African` = pbanc_afri,
    `Indigenous, any ancestry` = pind_totl,
    `Asian, any Asian ancestry` = parac_totl, 
    `Black,  any Black ancestry` = pbanc_totl,
    `Hispanic or Latino, any ancestry` = plat_totl,
    `Hispanic, Mexican` = plat_mexi,
    `Hispanic, Ecuadorian` = plat_ecua) %>%
  pivot_longer(names_to = "Race", values_to = "value", -c(tract_string, canopy_percent)) %>%
  ggplot(aes(x = value, y = canopy_percent)) +
  geom_point(pch = 21, col = "grey40") +#colors$suppGray) +
  geom_smooth(col = councilR::colors$cdGreen, fill = NA, lwd = 1, method = 'lm') +
  councilR::council_theme() +
    scale_y_continuous(labels = scales::percent, limits = c(0, .45))+#, trans = log2_trans()) +
  scale_x_continuous(labels = scales::percent)+#, trans = log2_trans()) +
  facet_wrap(~Race, scales = "free_x", ncol = 3) +
  labs(x = "Residents identifying with racial category (%)", y = "")

```

```{r}
eva_data_main %>%
  select(tract_string, variable, raw_value) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  select(tract_string, canopy_percent, 
         ppov185,
         ppov500,
         # mdhhincnow,
         phhi_qntl1,
         phhi_qntl5,
         # mdern_ftyr
         ) %>%
  rename(
   `Income < 185% poverty threshold` =  ppov185,
         `Income > 500% poverty threshold` = ppov500,
         # `Median household income ($)` = mdhhincnow,
         `Households in bottom quintile for income` = phhi_qntl1,
         `Households in top quintile for income` = phhi_qntl5,
         # `Median annual earnings for full-time workers ($)` = mdern_ftyr
   ) %>%
  pivot_longer(names_to = "Race", values_to = "value", -c(tract_string, canopy_percent)) %>%
  ggplot(aes(x = value, y = canopy_percent)) +
  geom_point(pch = 21, col = "grey40") +#colors$suppGray) +
  geom_smooth(col = councilR::colors$cdGreen, fill = NA, lwd = 1, method = 'lm') +
  councilR::council_theme() +
    scale_y_continuous(labels = scales::percent, limits = c(0, .45))+#, trans = log2_trans()) +
  scale_x_continuous(labels = scales::percent)+#, trans = log2_trans()) +
  facet_wrap(~Race, scales = "free_x", ncol = 2) +
  labs(x = "Households falling into income category (%)", y = "")


eva_data_main %>%
  select(tract_string, variable, raw_value) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  select(tract_string, canopy_percent, aca, acp) %>%
  rename(`Area of concentrated affluence` = aca,
         `Area of concentrated poverty` = acp) %>%
  pivot_longer(names_to = "Race", values_to = "value", -c(tract_string, canopy_percent)) %>%
  mutate(value = na_if(value, 0)) %>%
  filter(!is.na(value)) %>%
  ggplot(aes(x = Race, y = canopy_percent)) +
  ggdist::stat_halfeye(
          adjust = .5,  width = .3,  .width = 0,  justification = -.6, 
          point_colour = NA,
          na.rm = T) + 
        geom_boxplot(width = .25, outlier.shape = NA,
                     na.rm = T) +
        councilR::council_theme() +
        geom_point(size = 1.3,alpha = .3,
                   position = position_jitter(seed = 1, width = 0.1, height = 0),
                   col = "grey40",
                   na.rm = T) +
        labs( y = " ", x = "") +
        scale_y_continuous(labels = scales::percent_format(accuracy = 1))


mn_tracts %>% 
  right_join(eva_data_main %>%
  select(tract_string, variable, raw_value) %>%
  pivot_wider(names_from = variable, values_from = raw_value) %>%
  select(tract_string, canopy_percent, aca, acp) %>%
    filter(aca == 1)) %>%
  ggplot() +
  geom_sf(aes(fill = canopy_percent))
```



```{r treetrust-fig}
# https://www.bls.gov/cpi/tables/supplemental-files/historical-cpi-u-202111.pdf
cpi05 <- 193.2
cpi21 <-  266.236
tribble(~`Benefits`, ~`Total ($)`, ~`SE ($)`, ~`$/tree`, ~`SE ($/tree)`, ~`$/capita`, ~`SE ($/capita)`,
 "Energy", 6824046, (483981), 34.36, (2.44), 8.79, (.62),
 "CO2", 826875, (58644), 4.16, (.3), 1.06, (.08),
 "Air quality", 1134334, (80450), 5.71, (.41), 1.46, (.1),
 "Stormwater", 9071809, (643399), 45.67, (3.24), 11.68, (.83),
 "Aesthetic/Other", 7076370, (501877), 35.63, (2.53), 9.11, (.65),
"Total Benefits", 24933434, (1766384), 125.53, (8.89), 32.10, (2.27)) %>%
  mutate(Total21 = `$/tree` * cpi21/cpi05) %>%
  ggplot(aes(x = Total21, y = Benefits)) +
  geom_point()




```

Making it faster

```{r}
devtools::install_github("rstudio/profvis")
library(profvis)
```




